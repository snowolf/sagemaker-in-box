{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SageMaker Pipeline Demo"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo contains xgboost model regularly model training, deploy through SageMaker pipeline, and inference."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 02\n",
        "import sagemaker\n",
        "bucket = sagemaker.Session().default_bucket()\n",
        "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
        " \n",
        "# Define IAM role\n",
        "import boto3\n",
        "import re\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "role = get_execution_role()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 03\n",
        "import numpy as np                                # For matrix operations and numerical processing\n",
        "import pandas as pd                               # For munging tabular data\n",
        "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
        "from IPython.display import Image                 # For displaying images in the notebook\n",
        "from IPython.display import display               # For displaying outputs in the notebook\n",
        "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
        "import sys                                        # For writing outputs to notebook\n",
        "import math                                       # For ceiling function\n",
        "import json                                       # For parsing hosting outputs\n",
        "import os                                         # For manipulating filepath names\n",
        "import sagemaker \n",
        "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions\n",
        "\n",
        "import time"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sess = boto3.Session()\n",
        "sm = sess.client(\"sagemaker\")\n",
        "role = get_execution_role()\n",
        "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "region = boto3.Session().region_name\n",
        "model_package_group_name = \"xgboost-dir-mkt-bin-classification\"  # Model name in model registry\n",
        "prefix = \"xgboost-demo-pipelines\"\n",
        "pipeline_name = \"Xgboost-demo-pipelines\"  # SageMaker Pipeline name\n",
        "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
        "\n",
        "# # raw input data\n",
        "# input_data = ParameterString(name=\"InputData\", default_value=raw_s3)\n",
        "\n",
        "# # processing step parameters\n",
        "# processing_instance_type = ParameterString(\n",
        "#     name=\"ProcessingInstanceType\", default_value=\"ml.m5.large\"\n",
        "# )\n",
        "\n",
        "# training step parameters\n",
        "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.large\")\n",
        "training_epochs = ParameterString(name=\"TrainingEpochs\", default_value=\"100\")\n",
        "\n",
        "# # model performance step parameters\n",
        "# accuracy_mse_threshold = ParameterFloat(name=\"AccuracyMseThreshold\", default_value=0.75)\n",
        "\n",
        "# Inference step parameters\n",
        "endpoint_instance_type = ParameterString(name=\"EndpointInstanceType\", default_value=\"ml.m5.large\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model training step"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data_prefix = 'sagemaker/DEMO-xgboost-dm'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, data_prefix), content_type='csv')\n",
        "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, data_prefix), content_type='csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlow\n",
        "from sagemaker.inputs import TrainingInput\n",
        "from sagemaker.workflow.steps import TrainingStep\n",
        "from sagemaker.workflow.step_collections import RegisterModel\n",
        "import time\n",
        "\n",
        "model_path = f\"s3://{bucket}/{prefix}/model/\"\n",
        "\n",
        "\n",
        "xgb = sagemaker.estimator.Estimator(container,\n",
        "                                    role, \n",
        "                                    instance_count=1, \n",
        "                                    instance_type='ml.m4.xlarge',\n",
        "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
        "                                    sagemaker_session=sagemaker_session)\n",
        "xgb.set_hyperparameters(max_depth=5,\n",
        "                        eta=0.2,\n",
        "                        gamma=4,\n",
        "                        min_child_weight=6,\n",
        "                        subsample=0.8,\n",
        "                        silent=0,\n",
        "                        objective='binary:logistic',\n",
        "                        num_round=100,\n",
        "                        _kfold=5,\n",
        "                        _num_cv_round=3)\n",
        "\n",
        "step_train_model = TrainingStep(\n",
        "    name=\"xgb-model-training\",\n",
        "    estimator=xgb,\n",
        "    inputs={\n",
        "        \"train\": s3_input_train,\n",
        "        \"validation\": s3_input_validation,\n",
        "    },\n",
        ")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Model step"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# from sagemaker.workflow.step_collections import CreateModelStep\n",
        "\n",
        "model = sagemaker.model.Model(\n",
        "    image_uri=step_train_model.properties.AlgorithmSpecification.TrainingImage,\n",
        "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    role=role\n",
        "    )\n",
        "\n",
        "\n",
        "step_create_model = CreateModelStep(\n",
        "    name=\"Create-Xgboost-dir-mkt-Model\",\n",
        "    model=model,\n",
        "    inputs=sagemaker.inputs.CreateModelInput(instance_type=endpoint_instance_type),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy model to SageMaker Endpoint Lambda Step"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "When defining the LambdaStep, the SageMaker Lambda helper class provides helper functions for creating the Lambda function. Users can either use the lambda_func argument to provide the function ARN to an already deployed Lambda function OR use the Lambda class to create a Lambda function by providing a script, function name and role for the Lambda function.\n",
        "\n",
        "When passing inputs to the Lambda, the inputs argument can be used and within the Lambda function's handler, the event argument can be used to retrieve the inputs.\n",
        "\n",
        "The dictionary response from the Lambda function is parsed through the LambdaOutput objects provided to the outputs argument. The output_name in LambdaOutput corresponds to the dictionary key in the Lambda's return dictionary."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deploy_model_lambda.py\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This Lambda function deploys the model to SageMaker Endpoint. \n",
        "If Endpoint exists, then Endpoint will be updated with new Endpoint Config.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import boto3\n",
        "import time\n",
        "\n",
        "\n",
        "sm_client = boto3.client(\"sagemaker\")\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "\n",
        "    print(f\"Received Event: {event}\")\n",
        "\n",
        "    current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
        "    endpoint_instance_type = event[\"endpoint_instance_type\"]\n",
        "    model_name = event[\"model_name\"]\n",
        "    endpoint_config_name = \"{}-{}\".format(event[\"endpoint_config_name\"], current_time)\n",
        "    endpoint_name = event[\"endpoint_name\"]\n",
        "\n",
        "    # Create Endpoint Configuration\n",
        "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
        "        EndpointConfigName=endpoint_config_name,\n",
        "        ProductionVariants=[\n",
        "            {\n",
        "                \"InstanceType\": endpoint_instance_type,\n",
        "                \"InitialVariantWeight\": 1,\n",
        "                \"InitialInstanceCount\": 1,\n",
        "                \"ModelName\": model_name,\n",
        "                \"VariantName\": \"AllTraffic\",\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    print(f\"create_endpoint_config_response: {create_endpoint_config_response}\")\n",
        "\n",
        "    # Check if an endpoint exists. If no - Create new endpoint, if yes - Update existing endpoint\n",
        "    list_endpoints_response = sm_client.list_endpoints(\n",
        "        SortBy=\"CreationTime\",\n",
        "        SortOrder=\"Descending\",\n",
        "        NameContains=endpoint_name,\n",
        "    )\n",
        "    print(f\"list_endpoints_response: {list_endpoints_response}\")\n",
        "\n",
        "    if len(list_endpoints_response[\"Endpoints\"]) > 0:\n",
        "        print(\"Updating Endpoint with new Endpoint Configuration\")\n",
        "        update_endpoint_response = sm_client.update_endpoint(\n",
        "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
        "        )\n",
        "        print(f\"update_endpoint_response: {update_endpoint_response}\")\n",
        "    else:\n",
        "        print(\"Creating Endpoint\")\n",
        "        create_endpoint_response = sm_client.create_endpoint(\n",
        "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
        "        )\n",
        "        print(f\"create_endpoint_response: {create_endpoint_response}\")\n",
        "\n",
        "    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint Created Successfully\")}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Run only one time\n",
        "\n",
        "import boto3\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "iam = boto3.client('iam')\n",
        "\n",
        "def create_s3_lambda_role(role_name):\n",
        "    try:\n",
        "        response = iam.create_role(\n",
        "            RoleName = role_name,\n",
        "            AssumeRolePolicyDocument = json.dumps({\n",
        "                \"Version\": \"2012-10-17\",\n",
        "                \"Statement\": [\n",
        "                    {\n",
        "                        \"Effect\": \"Allow\",\n",
        "                        \"Principal\": {\n",
        "                            \"Service\": \"lambda.amazonaws.com\"\n",
        "                        },\n",
        "                        \"Action\": \"sts:AssumeRole\"\n",
        "                    }\n",
        "                ]\n",
        "            }),\n",
        "            Description='Role for Lambda to provide S3 read only access'\n",
        "        )\n",
        "\n",
        "        role_arn = response['Role']['Arn']\n",
        "\n",
        "        response = iam.attach_role_policy(\n",
        "            RoleName=role_name,\n",
        "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
        "        )\n",
        "\n",
        "        response = iam.attach_role_policy(\n",
        "            PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess',\n",
        "            RoleName=role_name\n",
        "        )\n",
        "\n",
        "        print('Waiting 30 seconds for the IAM role to propagate')\n",
        "        time.sleep(30)\n",
        "        return role_arn\n",
        "\n",
        "    except iam.exceptions.EntityAlreadyExistsException:\n",
        "        print(f'Using ARN from existing role: {role_name}')\n",
        "        response = iam.get_role(RoleName=role_name)\n",
        "        return response['Role']['Arn']\n",
        "    \n",
        "\n",
        "def create_sagemaker_lambda_role(role_name):\n",
        "    try:\n",
        "        response = iam.create_role(\n",
        "            RoleName = role_name,\n",
        "            AssumeRolePolicyDocument = json.dumps({\n",
        "                \"Version\": \"2012-10-17\",\n",
        "                \"Statement\": [\n",
        "                    {\n",
        "                        \"Effect\": \"Allow\",\n",
        "                        \"Principal\": {\n",
        "                            \"Service\": \"lambda.amazonaws.com\"\n",
        "                        },\n",
        "                        \"Action\": \"sts:AssumeRole\"\n",
        "                    }\n",
        "                ]\n",
        "            }),\n",
        "            Description='Role for Lambda to call SageMaker functions'\n",
        "        )\n",
        "\n",
        "        role_arn = response['Role']['Arn']\n",
        "\n",
        "        response = iam.attach_role_policy(\n",
        "            RoleName=role_name,\n",
        "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
        "        )\n",
        "\n",
        "        response = iam.attach_role_policy(\n",
        "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
        "            RoleName=role_name\n",
        "        )\n",
        "\n",
        "        print('Waiting 30 seconds for the IAM role to propagate')\n",
        "        time.sleep(30)\n",
        "        return role_arn\n",
        "\n",
        "    except iam.exceptions.EntityAlreadyExistsException:\n",
        "        print(f'Using ARN from existing role: {role_name}')\n",
        "        response = iam.get_role(RoleName=role_name)\n",
        "        return response['Role']['Arn']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Only create once\n",
        "\n",
        "lambda_role = create_sagemaker_lambda_role(\"deploy-model-lambda-role-sagemaker\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.workflow.lambda_step import LambdaStep\n",
        "from sagemaker.lambda_helper import Lambda\n",
        "\n",
        "endpoint_config_name = \"xgb-dir-mkt-endpoint-config\"\n",
        "endpoint_name = \"xgb-dir-endpoint-\" + current_time\n",
        "\n",
        "deploy_model_lambda_function_name = \"sagemaker-deploy-model-lambda-\" + current_time\n",
        "\n",
        "deploy_model_lambda_function = Lambda(\n",
        "    function_name=deploy_model_lambda_function_name,\n",
        "    execution_role_arn=lambda_role,\n",
        "    script=\"deploy_model_lambda.py\",\n",
        "    handler=\"deploy_model_lambda.lambda_handler\",\n",
        ")\n",
        "\n",
        "step_deploy_model_lambda = LambdaStep(\n",
        "    name=\"Deploy-Xgboost-dir-mkt-Endpoint\",\n",
        "    lambda_func=deploy_model_lambda_function,\n",
        "    inputs={\n",
        "        \"model_name\": step_create_model.properties.ModelName,\n",
        "        \"endpoint_config_name\": endpoint_config_name,\n",
        "        \"endpoint_name\": endpoint_name,\n",
        "        \"endpoint_instance_type\": endpoint_instance_type,\n",
        "    },\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline Creation: Orchestrate all steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.workflow.pipeline import Pipeline\n",
        "\n",
        "# Create a Sagemaker Pipeline.\n",
        "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
        "# Also pass in each of the steps created above.\n",
        "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
        "# not on the order they are passed in below.\n",
        "pipeline = Pipeline(\n",
        "    name=pipeline_name,\n",
        "    parameters=[\n",
        "        training_instance_type,\n",
        "        training_epochs,\n",
        "        endpoint_instance_type,\n",
        "    ],\n",
        "    steps=[step_train_model, step_create_model, step_deploy_model_lambda],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute the Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "definition = json.loads(pipeline.definition())\n",
        "definition"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.upsert(role_arn=role)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute pipeline using the default parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "execution = pipeline.start()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('validation.csv', header=None)\n",
        "test_data = test_data.drop([0], axis=1)\n",
        "\n",
        "data = test_data.iloc[1]\n",
        "payload = data.values.tolist()\n",
        "\n",
        "payload_new = [str(x) for x in payload]\n",
        "payload_new = ','.join(payload_new)\n",
        "payload_new"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "client = boto3.client('sagemaker-runtime')\n",
        "\n",
        "response=client.invoke_endpoint(EndpointName=endpoint_name,\n",
        "    Body=payload_new,\n",
        "    ContentType='text/csv'\n",
        "    # Accept='string',\n",
        "    )\n",
        "\n",
        "result = response['Body'].read()\n",
        "result = json.loads(result)\n",
        "print(result)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular trigger"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pipeline_execution_lambda.py\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This Lambda function execute sagemaker pipelines, it is triggered by EventBridge rules. \n",
        "\"\"\"\n",
        "\n",
        "import boto3\n",
        "import time\n",
        "\n",
        "client = boto3.client('sagemaker')\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "\n",
        "    print(f\"Received Event: {event}\")\n",
        "\n",
        "    current_time = time.strftime(\"%y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "    exec_display_name = 'xgb-dir-mkt-' + current_time\n",
        "\n",
        "    response = client.start_pipeline_execution(\n",
        "                PipelineName='Xgboost-demo-pipelines',\n",
        "                    PipelineExecutionDisplayName=exec_display_name,\n",
        "                        PipelineParameters=[\n",
        "                                    {\n",
        "                                        'Name': 'TrainingInstanceType',\n",
        "                                        'Value': 'ml.m5.large'\n",
        "                                    },\n",
        "                                    {\n",
        "                                        'Name': 'TrainingEpochs',\n",
        "                                        'Value': '100'\n",
        "                                    },\n",
        "                                    {\n",
        "                                        'Name': 'EndpointInstanceType',\n",
        "                                        'Value': 'ml.m5.large'\n",
        "                                    }\n",
        "                                        ],\n",
        "                          #  PipelineExecutionDescription='string',\n",
        "                          #      ClientRequestToken='string'\n",
        "                                )\n",
        "\n",
        "    print(response)\n",
        "    \n",
        "    return {\"statusCode\": 200, \"body\": response['PipelineExecutionArn']}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.lambda_helper import Lambda\n",
        "\n",
        "\n",
        "\n",
        "pipeline_exec_lambda_function_name = \"sagemaker-pipeline-exec-lambda\"\n",
        "\n",
        "pipeline_exec_lambda_function = Lambda(\n",
        "    function_name=pipeline_exec_lambda_function_name,\n",
        "    execution_role_arn=lambda_role,\n",
        "    script=\"pipeline_execution_lambda.py\",\n",
        "    handler=\"pipeline_execution_lambda.lambda_handler\",\n",
        ")\n",
        "\n",
        "print(pipeline_exec_lambda_function.create())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EventBus to trigger"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}